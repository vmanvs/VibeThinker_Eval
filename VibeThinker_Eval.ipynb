{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMV2ZKSEr+Ff6HtpbsxFp5o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmanvs/VibeThinker_Eval/blob/main/VibeThinker_Eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdIvgOyKdqXF",
        "outputId": "afa93d09-cc31-4d81-cd0f-ebdd8a0cbba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Running in Google Colab\n",
            "\n",
            "GPU Available: True\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory:  14.7 GB\n",
            "\n",
            "============================================================\n",
            "Installing dependencies\n",
            "============================================================\n",
            "✓ Dependencies installed\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "#Check env\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  print(\"✓ Running in Google Colab\")\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "  print(\"⚠ Not running in Colab - some features may not work\")\n",
        "\n",
        "#Check GPU\n",
        "import torch\n",
        "print(f\"\\nGPU Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "  print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3: .1f} GB\")\n",
        "\n",
        "else:\n",
        "  print(\"No GPU Found! Change the Runtime\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Installing dependencies\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!pip install -q transformers accelerate bitsandbytes sentencepiece termcolor huggingface_hub --upgrade bitsandbytes\n",
        "\n",
        "print(\"✓ Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount G-Drive for saving and fetching data\n",
        "import os\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "if IN_COLAB:\n",
        "  from google.colab import drive\n",
        "  print(\"\\nMounting G Drive...\")\n",
        "  print(\"Authorization Required\")\n",
        "  drive.mount('/content/drive')\n",
        "  print(\"✓ Google Drive mounted at /content/drive\")\n",
        "\n",
        "  #Create an output Dir\n",
        "  OUTPUT_DIR = \"/content/drive/MyDrive/ToolBench_Results/vibethinker_predictions\"\n",
        "  os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "  print(f\"✓ Results will be saved to: {OUTPUT_DIR}\")\n",
        "\n",
        "  CACHE_DIR = \"/content/stable_toolbench_cache\"\n",
        "  os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "  print(\"Downloading API cache (~2-3GB, takes 5-10 min)...\")\n",
        "  print(\"⏳ Please wait...\")\n",
        "\n",
        "  cache_path = snapshot_download(\n",
        "    repo_id=\"THUNLP-MT/StableToolBench\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=CACHE_DIR,\n",
        "    allow_patterns=[\n",
        "        \"tool_response_cache/*\",\n",
        "        \"tools/*\"\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  print(f\"✓ Cache downloaded to: {cache_path}\")\n",
        "  assert os.path.exists(f\"{CACHE_DIR}/tool_response_cache\"), \"Cache missing!\"\n",
        "  assert os.path.exists(f\"{CACHE_DIR}/tools\"), \"Tools missing!\"\n",
        "  print(\"✓ Cache structure verified\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "Q6yDfNWAwW84",
        "outputId": "7a179603-632d-4412-acdc-6c7fa3e92123"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mounting G Drive...\n",
            "Authorization Required\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✓ Google Drive mounted at /content/drive\n",
            "✓ Results will be saved to: /content/drive/MyDrive/ToolBench_Results/vibethinker_predictions\n",
            "Downloading API cache (~2-3GB, takes 5-10 min)...\n",
            "⏳ Please wait...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RepositoryNotFoundError",
          "evalue": "404 Client Error. (Request ID: Root=1-69276468-669dca68235c251756da70bf;afddedc1-a6f9-4620-ae59-0f7ae43cca7a)\n\nRepository Not Found for url: https://huggingface.co/api/datasets/THUNLP-MT/StableToolBench/revision/main.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/api/datasets/THUNLP-MT/StableToolBench/revision/main",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4233665082.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"⏳ Please wait...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   cache_path = snapshot_download(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"THUNLP-MT/StableToolBench\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\u001b[0m in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[0m\n\u001b[1;32m    243\u001b[0m         ):\n\u001b[1;32m    244\u001b[0m             \u001b[0;31m# Repo not found, gated, or specific authentication error => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mapi_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;31m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\u001b[0m in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;31m# if we have internet connection we want to list files to download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mrepo_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProxyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;31m# Actually raise for those subclasses of ConnectionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mrepo_info\u001b[0;34m(self, repo_id, revision, repo_type, timeout, files_metadata, expand, token)\u001b[0m\n\u001b[1;32m   2865\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported repo type.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2867\u001b[0;31m         return method(\n\u001b[0m\u001b[1;32m   2868\u001b[0m             \u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mdataset_info\u001b[0;34m(self, repo_id, revision, timeout, files_metadata, expand, token)\u001b[0m\n\u001b[1;32m   2729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2731\u001b[0;31m         \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2732\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;34m\" https://huggingface.co/docs/huggingface_hub/authentication\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             )\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-69276468-669dca68235c251756da70bf;afddedc1-a6f9-4620-ae59-0f7ae43cca7a)\n\nRepository Not Found for url: https://huggingface.co/api/datasets/THUNLP-MT/StableToolBench/revision/main.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clone ToolBench Repo\n",
        "print(\"\\n\"+\"=\"*60)\n",
        "print(\"Setting up ToolBench...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "#Check if already present\n",
        "if not os.path.exists(\"/content/ToolBench\"):\n",
        "  print(\"Cloning ToolBech...\")\n",
        "  !git clone https://github.com/vmanvs/Fixed_ToolBench /content/ToolBench\n",
        "  print(\"✓ ToolBench cloned\")\n",
        "else:\n",
        "  print(\"✓ ToolBench already exists\")\n",
        "\n",
        "#Add to path\n",
        "sys.path.insert(0, \"/content/ToolBench\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wYJVs5fqy2ai",
        "outputId": "4573b876-e16d-46ff-f7fb-800e3324e257"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Setting up ToolBench...\n",
            "============================================================\n",
            "Cloning ToolBech...\n",
            "Cloning into '/content/ToolBench'...\n",
            "remote: Enumerating objects: 1286, done.\u001b[K\n",
            "remote: Total 1286 (delta 0), reused 0 (delta 0), pack-reused 1286 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1286/1286), 58.93 MiB | 30.23 MiB/s, done.\n",
            "Resolving deltas: 100% (749/749), done.\n",
            "✓ ToolBench cloned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download test data\n",
        "print(\"\\n\"+\"=\"*60)\n",
        "print(\"Downloading test data...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "#Recommended have the test data in G Drive\n",
        "\"\"\"\n",
        "The data shoulde be placed as such:\n",
        "MyDrive/\n",
        "   ├── ToolBench_Data/\n",
        "   │   ├── test_instruction/\n",
        "   │   │   ├── G1_instruction.json\n",
        "   │   │   ├── G1_category.json\n",
        "   │   │   ├── G1_tool.json\n",
        "   │   │   ├── G2_category.json\n",
        "   │   │   ├── G2_instruction.json\n",
        "   │   │   └── G3_instruction.json\n",
        "   │   └── toolenv/\n",
        "   │       └── tools/\n",
        "   │           ├── Advertising/\n",
        "   │           │   └── tool1.json\n",
        "   |           |   └──...\n",
        "   │           ├── Artificial_Intelligence_Machine_Learning/\n",
        "   │           |    └── tool2.json\n",
        "   |           |   └──...\n",
        "\"\"\"\n",
        "TEST_DATA_DIR = \"/content/drive/MyDrive/ToolBench_Data/test_instruction\"\n",
        "\n",
        "#Option B:\n",
        "#!wget -O /content/test_data.zip \"https://drive.google.com/drive/folders/1TysbSWYpP8EioFu9xPJtpbJZMLLmwAmL\"\n",
        "#!unzip /content/test_data.zip -d /content/\n",
        "\n",
        "if not os.path.exists(TEST_DATA_DIR):\n",
        "  print(\"⚠ Test data not found!\")\n",
        "else:\n",
        "  print(f\"✓ Test data found at: {TEST_DATA_DIR}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FX5pXtdL0df7",
        "outputId": "3ba42f07-ce0a-485c-9b9e-734c0027d74f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Downloading test data...\n",
            "============================================================\n",
            "✓ Test data found at: /content/drive/MyDrive/ToolBench_Data/test_instruction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the following error persists even after re-running all cells:\n",
        "```bash\n",
        "     86             raise ImportError(\n",
        "     87                 \"Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\"\n",
        "     88 )\n",
        "```\n",
        "Consider restarting the runtime...\n"
      ],
      "metadata": {
        "id": "oUsq4SNN_dz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create cache handler\n",
        "\n",
        "cache_handler_code = \"\"\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "class StableToolBenchCache:\n",
        "\n",
        "  #Handler for cached API responses\n",
        "\n",
        "  def __init__(self, cache_dir):\n",
        "    self.cache_dir = Path(cache_dir)\n",
        "    self.tool_response_cache = self.cache_dir / \"tool_response_cache\"\n",
        "    self.tools = self.cache_dir / \"tools\"\n",
        "\n",
        "    if not self.tool_response_cache.exists():\n",
        "      raise ValueError(f\"Cache directory {self.tool_response_cache} does not exist\")\n",
        "\n",
        "    print(f\"✓ Cache initialized at: {self.tool_response_cache}\")\n",
        "    self.load_cache_stats()\n",
        "\n",
        "  def load_cache_stats(self):\n",
        "\n",
        "    #Count cached responses\n",
        "\n",
        "\n",
        "    cache_files = list(self.tool_response_cache.glob(\"*.json\"))\n",
        "    print(f\"✓ Found {len(cache_files)} cache files\")\n",
        "\n",
        "    total_entries = 0\n",
        "    for cache_file in cache_files[:5]: #Sample first 5\n",
        "      try:\n",
        "        with open(cache_file, \"r\") as f:\n",
        "          data = json.load(f)\n",
        "          total_entries += len(data) if isinstance(data, list) else 1\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    print(f\"   Estimated {total_entries * len(cache_files)//5} cached API responses\")\n",
        "\n",
        "\n",
        "  def get_cached_response(self, category, tool_name, api_name, params):\n",
        "\n",
        "    #Get cached response for a given API call\n",
        "\n",
        "    #Args:\n",
        "      #category: API category (e.g., \"Weather\")\n",
        "      #tool_name: Tool name (e.g., \"OpenWeatherMap\")\n",
        "      #api_name: API endpoint name\n",
        "      #params: Dictionary of parameters\n",
        "\n",
        "    #Returns:\n",
        "      #Cached response if found, otherwise None\n",
        "\n",
        "\n",
        "    #Create cache key\n",
        "    cache_key = self._create_cache_key(category, tool_name, api_name, params)\n",
        "\n",
        "    #Check if cache file exists\n",
        "    cache_file = self.tool_response_cache / f\"{category}_{tool_name}.json\"\n",
        "\n",
        "    if not cache_file.exists():\n",
        "      return None\n",
        "\n",
        "    #Load cache\n",
        "    try:\n",
        "      with open(cache_file, \"r\") as f:\n",
        "        cache_data = json.load(f)\n",
        "\n",
        "      #Search for matching entry\n",
        "      for entry in cache_data:\n",
        "        if entry.get(\"cache_key\") == cache_key:\n",
        "          return entry.get(\"response\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error reading cache: {e}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "  def _create_cache_key(self, category, tool_name, api_name, params):\n",
        "\n",
        "    #Create cache key\n",
        "\n",
        "    params_str = json.dumps(params, sort_keys=True)\n",
        "    return f\"{category}::{tool_name}::{api_name}::{params_str}\"\n",
        "\n",
        "#Save to file\n",
        "cache_handler_path = \"/content/stable_cache_handler.py\"\n",
        "with open(cache_handler_path, \"w\") as f:\n",
        "  f.write(__doc__)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/stable_cache_handler.py\", \"w\") as f:\n",
        "  f.write(cache_handler_code)\n",
        "\n",
        "print(\"✓ Cache handler created\")\n"
      ],
      "metadata": {
        "id": "Kt4ta5Bvrxa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Modified ToolBench runner with cache support\n",
        "\n",
        "print(\"\\n\"+\"=\"*60)\n",
        "print(\"Creating modified ToolBench Runner...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "runner_code = \"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/ToolBench\")\n",
        "\n",
        "from stable_cache_handler import StableToolBenchCache\n",
        "from toolbench.inference.Downstream_tasks.rapidapi import pipeline_runner\n",
        "\n",
        "class CachedPipelineRunner(pipeline_runner):\n",
        "\n",
        "  #Extended pipeline runner with cache support\n",
        "\n",
        "  def __init__(self, *args, cache_dir=None,**kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "\n",
        "    if cache_dir:\n",
        "      self.cache = StableToolBenchCache(self.cache_dir)\n",
        "      print(\"✓ Cache enabled for evaluation\")\n",
        "    else:\n",
        "      self.cache = None\n",
        "\n",
        "  def query_tool(self, category, tool_name, api_name, params):\n",
        "\n",
        "    #Override to check cache first\n",
        "\n",
        "\n",
        "    #Try cache first\n",
        "    if self.cache:\n",
        "      cached_response = self.cache.get_cached_response(category, tool_name, api_name, params)\n",
        "      if cached_response:\n",
        "        return cached_response\n",
        "\n",
        "    #Fallback to original method\n",
        "    return super().query_tool(category, tool_name, api_name, params)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/cached_runner.py\", \"w\") as f:\n",
        "  f.write(runner_code)\n",
        "\n",
        "print(\"✓ Cache-enabled runner created\")\n"
      ],
      "metadata": {
        "id": "5pL34-i6x-bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load VibeThinker\n",
        "print(\"\\n\"+\"=\"*60)\n",
        "print(\"Loading VibeThinker Model\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from typing import Optional, List\n",
        "import bitsandbytes\n",
        "import re\n",
        "import torch\n",
        "import json\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "MODEL_NAME = \"WeiboAI/VibeThinker-1.5B\"\n",
        "\n",
        "# UPDATED: Full ToolBench-compatible wrapper\n",
        "class VibeThinkerWrapper:\n",
        "  \"\"\"\n",
        "  Enhanced wrapper with agressive prompt enginnering for tool use\n",
        "  \"\"\"\n",
        "  def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = model.device\n",
        "        self.conversation_history = []\n",
        "        self.time = None\n",
        "\n",
        "  def prediction(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "      \"\"\"\n",
        "      Main inference method called by ToolBench\n",
        "      \"\"\"\n",
        "      with torch.no_grad():\n",
        "          inputs = self.tokenizer(\n",
        "              prompt,\n",
        "              return_tensors=\"pt\",\n",
        "              padding=True,\n",
        "              truncation=True,\n",
        "              max_length=2048\n",
        "          ).to(self.device)\n",
        "\n",
        "          outputs = self.model.generate(\n",
        "              **inputs,\n",
        "              max_new_tokens=256,\n",
        "              do_sample=True,\n",
        "              temperature=0.3,\n",
        "              top_p=0.85,\n",
        "              top_k=40,\n",
        "              repetition_penalty=1.2,\n",
        "              pad_token_id=self.tokenizer.eos_token_id,\n",
        "              eos_token_id=self.tokenizer.eos_token_id\n",
        "          )\n",
        "\n",
        "          input_len = inputs['input_ids'].shape[1]\n",
        "          generated_tokens = outputs[0, input_len:]\n",
        "          response = self.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "          return response.strip()\n",
        "\n",
        "  def add_message(self, message):\n",
        "      \"\"\"\n",
        "      Add a single message to conversation history\n",
        "      Called by ToolBench to build conversation\n",
        "      \"\"\"\n",
        "      self.conversation_history.append(message)\n",
        "\n",
        "  def change_messages(self, messages):\n",
        "      \"\"\"\n",
        "      Replace entire conversation history\n",
        "      Called by ToolBench at the start of each chain step\n",
        "      \"\"\"\n",
        "      self.conversation_history = messages\n",
        "\n",
        "  def display_conversation(self, detailed=False):\n",
        "      \"\"\"\n",
        "      Debug method to print conversation\n",
        "      Optional but helpful for debugging\n",
        "      \"\"\"\n",
        "      try:\n",
        "        from termcolor import colored\n",
        "\n",
        "        role_to_color = {\n",
        "            \"system\": \"red\",\n",
        "            \"user\": \"green\",\n",
        "            \"assistant\": \"blue\",\n",
        "            \"function\": \"magenta\",\n",
        "        }\n",
        "\n",
        "        print(\"Conversation \" + \"=\"*50)\n",
        "        for message in self.conversation_history:\n",
        "            role = message.get('role', 'unknown')\n",
        "            content = message.get('content', '')\n",
        "\n",
        "            print_obj = f\"{role}: {content[:100]}...\"\n",
        "\n",
        "            if \"function_call\" in message:\n",
        "                print_obj += f\" | function_call: {message['function_call']}\"\n",
        "\n",
        "            color = role_to_color.get(role, \"white\")\n",
        "            print(colored(print_obj, color))\n",
        "\n",
        "        print(\"=\"*60)\n",
        "      except:\n",
        "        pass #fail silently if termcolor not found\n",
        "\n",
        "  def parse(self, functions, process_id, **args):\n",
        "      \"\"\"\n",
        "      Main parsing method called by ToolBench's agent loop\n",
        "\n",
        "      This method:\n",
        "      1. Builds prompt from conversation history\n",
        "      2. Calls prediction()\n",
        "      3. Enhanced Prompt Construction\n",
        "      4. Parses the response for Action/Thought\n",
        "      5. Returns in ToolBench's expected format\n",
        "      \"\"\"\n",
        "      import time\n",
        "      import json\n",
        "\n",
        "      self.time = time.time()\n",
        "\n",
        "      # Build prompt from conversation history\n",
        "      prompt = self._build_enhanced_prompt(self.conversation_history, functions)\n",
        "\n",
        "      # Get model prediction\n",
        "      predictions = self.prediction(prompt)\n",
        "\n",
        "      if process_id == 0:\n",
        "          # Estimate token count (rough approximation)\n",
        "          decoded_token_len = len(self.tokenizer.encode(predictions))\n",
        "          print(f\"[process({process_id})]total tokens: {decoded_token_len}\")\n",
        "      else:\n",
        "          decoded_token_len = 0\n",
        "\n",
        "      # Parse the prediction into ToolBench's format\n",
        "      thought, action, action_input = self._enhanced_react_parser(predictions, functions)\n",
        "\n",
        "      # Return in expected format: (message_dict, error_code, token_count)\n",
        "      message = {\n",
        "          \"role\": \"assistant\",\n",
        "          \"content\": thought,\n",
        "          \"function_call\": {\n",
        "              \"name\": action,\n",
        "              \"arguments\": action_input\n",
        "          }\n",
        "      }\n",
        "\n",
        "      return message, 0, decoded_token_len\n",
        "\n",
        "  def _build_enhanced_prompt(self, messages, functions):\n",
        "    \"\"\"\n",
        "    Build prompt with strong formatting instructions and examples\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = \"\"\n",
        "    #Track if we we've seen the system\n",
        "\n",
        "    has_system = False\n",
        "    user_query = \"\"\n",
        "\n",
        "    for message in messages:\n",
        "      role = message.get('role', '')\n",
        "      content = message.get('content', '')\n",
        "\n",
        "      if role == \"system\":\n",
        "        has_system = True\n",
        "        #Inject enhanced instructions\n",
        "        enhanced_system = self._create_enhanced_system_prompt(content, functions)\n",
        "        prompt += f\"{enhanced_system}\\n\\n\"\n",
        "\n",
        "      elif role == \"user\":\n",
        "        user_query = content\n",
        "        prompt += f\"USER QUESTION: {content}\\n\\n\"\n",
        "\n",
        "      elif role == 'assistant':\n",
        "        prompt += f\"ASSISTANT RESPONSE:\\n{content}\\n\\n\"\n",
        "\n",
        "      elif role == 'function':\n",
        "        prompt += f\"TOOL RESULT: {content}\\n\\n\"\n",
        "\n",
        "    #Add strong formatting reminder before assistant response\n",
        "    prompt += self._get_format_reminder(functions)\n",
        "\n",
        "    return prompt\n",
        "\n",
        "  def _create_enhanced_system_prompt(self, original_content, functions):\n",
        "    \"\"\"\n",
        "    Create a explicit system prompt with examples\n",
        "    \"\"\"\n",
        "\n",
        "    system_prompt = \"\"\"\n",
        "    You are a helpful AI assistant that uses tools to answer questions.\n",
        "\n",
        "    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "    CRITICAL: YOU MUST RESPOND IN THIS EXACT FORMAT - NO EXCEPTIONS:\n",
        "    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "\n",
        "    FORMAT TEMPLATE:\n",
        "    Thought: [One sentence explaining what you need to do]\n",
        "    Action: [exact_tool_name]\n",
        "    Action Input: {\"param1\": \"value1\", \"param2\": \"value2\"}\n",
        "\n",
        "    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "    CONCRETE EXAMPLES:\n",
        "    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "\n",
        "    EXAMPLE 1 - Using a weather tool:\n",
        "    USER: What's the weather in Paris?\n",
        "    ASSISTANT:\n",
        "    Thought: I need to check the weather for Paris using the weather tool.\n",
        "    Action: get_weather\n",
        "    Action Input: {\"city\": \"Paris\", \"country\": \"France\"}\n",
        "\n",
        "    [After getting weather data...]\n",
        "    Thought: I have received the weather information for Paris.\n",
        "    Action: Finish\n",
        "    Action Input: {\"return_type\": \"give_answer\", \"final_answer\": \"The weather in Paris is sunny with a temperature of 22°C.\"}\n",
        "\n",
        "    EXAMPLE 2 - Searching for flights:\n",
        "    USER: Find flights from London to Dubai\n",
        "    ASSISTANT:\n",
        "    Thought: I need to search for available flights between London and Dubai.\n",
        "    Action: search_flights\n",
        "    Action Input: {\"origin\": \"London\", \"destination\": \"Dubai\", \"date\": \"2024-01-15\"}\n",
        "\n",
        "    [After getting flight results...]\n",
        "    Thought: I found flight options and can provide the answer.\n",
        "    Action: Finish\n",
        "    Action Input: {\"return_type\": \"give_answer\", \"final_answer\": \"Found 3 flights from London to Dubai with prices ranging from $450 to $680.\"}\n",
        "\n",
        "    EXAMPLE 3 - When you can't complete the task:\n",
        "    USER: [Impossible request]\n",
        "    ASSISTANT:\n",
        "    Thought: I cannot complete this task with the available tools.\n",
        "    Action: Finish\n",
        "    Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
        "\n",
        "    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "    IMPORTANT RULES:\n",
        "    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "\n",
        "    1. ALWAYS start with \"Thought:\"\n",
        "    2. ALWAYS follow with \"Action:\" on a new line\n",
        "    3. ALWAYS follow with \"Action Input:\" on a new line with valid JSON\n",
        "    4. Keep Thought to ONE sentence\n",
        "    5. Action must be EXACTLY one of the tool names listed below\n",
        "    6. Action Input must be valid JSON with correct parameters\n",
        "    7. When you have the final answer, use Action: Finish\n",
        "\n",
        "    \"\"\"\n",
        "      #Add available tools\n",
        "    if functions:\n",
        "      system_prompt += \"\\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\"\n",
        "      system_prompt += \"AVAILABLE TOOLS:\\n\"\n",
        "      system_prompt += \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\\n\"\n",
        "\n",
        "\n",
        "      for i, func in enumerate(functions, 1):\n",
        "        name = func.get('name', 'unknown')\n",
        "        desc = func.get('description', 'No description')\n",
        "        params = func.get('parameters', {}).get('properties', {})\n",
        "        required = func.get('parameters', {}).get('required', [])\n",
        "\n",
        "        system_prompt += f\"{i}. Tool Name: {name}\\n\"\n",
        "        system_prompt += f\"  Description: {desc}\\n\"\n",
        "\n",
        "        if params:\n",
        "          system_prompt += f\"    Parameters:\\n\"\n",
        "          for param_name, param_info in params.items():\n",
        "            param_type = param_info.get('type', 'string')\n",
        "            param_desc = param_info.get('description', '')\n",
        "            is_required = \"    (REQUIRED)\" if param_name in required else \"(optional)\"\n",
        "            system_prompt += f\"      - {param_name}: {param_type}{is_required} - {param_desc}\\n\"\n",
        "\n",
        "        system_prompt += \"\\n\"\n",
        "\n",
        "    return system_prompt\n",
        "\n",
        "  def _get_format_reminder(self, functions) -> str:\n",
        "    \"\"\"\n",
        "    Strong reminder right before the model generates\n",
        "    \"\"\"\n",
        "    tool_names = [f['name'] for f in functions] if functions else []\n",
        "    tool_list = \", \".join(tool_names[:5])\n",
        "\n",
        "    if len(tool_names) > 5:\n",
        "      tool_list += f\", ...({len(tool_names)} total)\"\n",
        "\n",
        "    reminder = f\"\"\"\n",
        "          ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "          REMINDER: You must respond in this EXACT format:\n",
        "\n",
        "          Thought: [one sentence]\n",
        "          Action: [choose from: {tool_list}]\n",
        "          Action Input: {{\"param\": \"value\"}}\n",
        "\n",
        "          Now respond:\n",
        "          ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "\n",
        "          ASSISTANT RESPONSE:\n",
        "      \"\"\"\n",
        "\n",
        "    return reminder #if remainder is not None else return \"\"\n",
        "\n",
        "\n",
        "  def _inject_functions_into_system(self, system_content, functions):\n",
        "      \"\"\"\n",
        "      Add function descriptions to system prompt\n",
        "      \"\"\"\n",
        "      if not functions:\n",
        "          return system_content\n",
        "\n",
        "      func_desc = \"\\n\\nAvailable functions:\\n\"\n",
        "      for func in functions:\n",
        "          name = func.get('name', 'unknown')\n",
        "          desc = func.get('description', 'No description')\n",
        "          params = func.get('parameters', {}).get('properties', {})\n",
        "\n",
        "          func_desc += f\"\\n{name}: {desc}\\n\"\n",
        "          if params:\n",
        "              func_desc += f\"  Parameters: {list(params.keys())}\\n\"\n",
        "\n",
        "      return system_content + func_desc\n",
        "\n",
        "  def _enhanced_react_parser(self, text, functions):\n",
        "    \"\"\"\n",
        "      Enhanced parser with multiple fallback strategies\n",
        "    \"\"\"\n",
        "    #1. Try standard parsing\n",
        "    thought, action, action_input = self._standard_react_parser(text)\n",
        "\n",
        "    if action and action!=\"Finish\":\n",
        "      #Validate action exists\n",
        "      valid_actions = [f['name'] for f in functions] + ['Finish']\n",
        "      if action not in valid_actions:\n",
        "        #2. try fuzzy matching\n",
        "        action = self._fuzzy_match_action(action, valid_actions)\n",
        "\n",
        "    #Strategy 3: If still no valid action, extract intent\n",
        "    if not action or (action not in [f['name'] for f in functions] and action != 'Finish'):\n",
        "        thought, action, action_input = self._intent_extraction(text, functions)\n",
        "\n",
        "    #Last option: Give up grace fully\n",
        "    if not action:\n",
        "      thought = text[:200] if text else \"I cannot determine appropriate action.\"\n",
        "      action = \"Finish\"\n",
        "      action_input = json.dumps({\n",
        "          \"return_type\": \"give_up_and_restart\"\n",
        "      })\n",
        "\n",
        "    return thought, action, action_input\n",
        "\n",
        "  def _standard_react_parser(self, text):\n",
        "      \"\"\"\n",
        "      Parse model output in ReAct format\n",
        "\n",
        "      Expected format:\n",
        "      Thought: <reasoning>\n",
        "      Action: <function_name>\n",
        "      Action Input: <json_input>\n",
        "\n",
        "      Or:\n",
        "\n",
        "      Final Answer: <answer>\n",
        "      \"\"\"\n",
        "      thought = \"\"\n",
        "      action = \"\"\n",
        "      action_input = \"\"\n",
        "\n",
        "      text = text.strip()\n",
        "\n",
        "      # Try to extract Thought\n",
        "      thought_patterns = [\n",
        "        r'Thought:\\s*(.+?)(?=Action:|$)',\n",
        "        r'THOUGHT:\\s*(.+?)(?=ACTION:|$)',\n",
        "        r'Thought:\\s*(.+?)(?=Action Input:|$)',\n",
        "        r'THOUGHT:\\s*(.+?)(?=ACTION INPUT:|$)',\n",
        "        #Fallback match everything before Action\n",
        "        r'^(.+?)(?=Action:|$)',\n",
        "        r'^(.+?)(?=Action Input:|$)'\n",
        "      ]\n",
        "\n",
        "      for pattern in thought_patterns:\n",
        "        match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "        if match:\n",
        "          thought = match.group(1).strip()\n",
        "          thought = thought.split('\\n')[0][:200]\n",
        "          break\n",
        "\n",
        "      # Extract Action\n",
        "      action_patterns = [\n",
        "          r'Action:\\s*([^\\n]+)',\n",
        "          r'ACTION:\\s*([^\\n]+)',\n",
        "          r'Tool:\\s*([^\\n]+)',\n",
        "      ]\n",
        "\n",
        "      for pattern in action_patterns:\n",
        "          match = re.search(pattern, text, re.IGNORECASE)\n",
        "          if match:\n",
        "              action = match.group(1).strip()\n",
        "              # Remove any trailing punctuation or quotes\n",
        "              action = re.sub(r'[\"\\'\\.,;:]+$', '', action)\n",
        "              break\n",
        "\n",
        "      # Extract Action Input\n",
        "      input_patterns = [\n",
        "          r'Action Input:\\s*(\\{.+?\\})',\n",
        "          r'ACTION INPUT:\\s*(\\{.+?\\})',\n",
        "          r'Input:\\s*(\\{.+?\\})',\n",
        "          r'(\\{[^}]+\\})',  # Any JSON object\n",
        "      ]\n",
        "\n",
        "      for pattern in input_patterns:\n",
        "          match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "          if match:\n",
        "              action_input = match.group(1).strip()\n",
        "              # Validate JSON\n",
        "              try:\n",
        "                  json.loads(action_input)\n",
        "                  break\n",
        "              except:\n",
        "                  continue\n",
        "\n",
        "      # Check for final answer indicators\n",
        "      if any(keyword in text.lower() for keyword in ['final answer', 'final_answer', 'give_answer', 'answer is']):\n",
        "          action = \"Finish\"\n",
        "\n",
        "          # Extract the answer\n",
        "          answer_match = re.search(r'(?:final answer|answer is)[:\\s]*(.+)', text, re.IGNORECASE | re.DOTALL)\n",
        "          if answer_match:\n",
        "              answer = answer_match.group(1).strip()[:500]\n",
        "          else:\n",
        "              answer = thought if thought else text[:500]\n",
        "\n",
        "          action_input = json.dumps({\n",
        "              \"return_type\": \"give_answer\",\n",
        "              \"final_answer\": answer\n",
        "          })\n",
        "\n",
        "      # Check for give up indicators\n",
        "      if any(keyword in text.lower() for keyword in ['cannot', 'unable', 'give up', 'don\\'t know', 'not possible']):\n",
        "          if not action or action == \"Finish\":\n",
        "              action = \"Finish\"\n",
        "              action_input = json.dumps({\n",
        "                  \"return_type\": \"give_up_and_restart\"\n",
        "              })\n",
        "\n",
        "      return thought, action, action_input\n",
        "      \"\"\"\n",
        "      if \"Thought:\" in text:\n",
        "          thought_start = text.find(\"Thought:\") + len(\"Thought:\")\n",
        "          thought_end = text.find(\"Action:\", thought_start)\n",
        "          if thought_end == -1:\n",
        "              thought_end = text.find(\"Final Answer:\", thought_start)\n",
        "          if thought_end == -1:\n",
        "              thought_end = len(text)\n",
        "          thought = text[thought_start:thought_end].strip()\n",
        "\n",
        "      # Try to extract Action\n",
        "      if \"Action:\" in text:\n",
        "          action_start = text.find(\"Action:\") + len(\"Action:\")\n",
        "          action_end = text.find(\"Action Input:\", action_start)\n",
        "          if action_end == -1:\n",
        "              action_end = text.find(\"\\n\", action_start)\n",
        "          if action_end == -1:\n",
        "              action_end = len(text)\n",
        "          action = text[action_start:action_end].strip()\n",
        "\n",
        "      # Try to extract Action Input\n",
        "      if \"Action Input:\" in text:\n",
        "          input_start = text.find(\"Action Input:\") + len(\"Action Input:\")\n",
        "          action_input = text[input_start:].strip()\n",
        "\n",
        "          # Try to parse as JSON\n",
        "          try:\n",
        "              # Find JSON object\n",
        "              if \"{\" in action_input:\n",
        "                  json_start = action_input.find(\"{\")\n",
        "                  json_end = action_input.rfind(\"}\") + 1\n",
        "                  action_input = action_input[json_start:json_end]\n",
        "          except:\n",
        "              pass\n",
        "\n",
        "      # Check for Final Answer\n",
        "      if \"Final Answer:\" in text or \"final answer\" in text.lower():\n",
        "          action = \"Finish\"\n",
        "          # Extract the answer\n",
        "          if \"Final Answer:\" in text:\n",
        "              answer_start = text.find(\"Final Answer:\") + len(\"Final Answer:\")\n",
        "              answer = text[answer_start:].strip()\n",
        "          else:\n",
        "              answer = thought if thought else text\n",
        "\n",
        "          action_input = json.dumps({\n",
        "              \"return_type\": \"give_answer\",\n",
        "              \"final_answer\": answer\n",
        "          })\n",
        "\n",
        "      # If no action found, assume the model wants to give up or is confused\n",
        "      if not action and not thought:\n",
        "          thought = text\n",
        "          action = \"Finish\"\n",
        "          action_input = json.dumps({\n",
        "              \"return_type\": \"give_up_and_restart\"\n",
        "          })\n",
        "\n",
        "      return thought, action, action_input\n",
        "      \"\"\"\n",
        "  def _fuzzy_match_action(self, action, valid_actions):\n",
        "    \"\"\"\n",
        "    Try to match action to valid actions using fuzzy matching\n",
        "    \"\"\"\n",
        "    action_lower = action.lower().replace('_','').replace('_','')\n",
        "\n",
        "    for valid_action in valid_actions:\n",
        "      valid_lower = valid_action.lower().replace('_','').replace('_','')\n",
        "\n",
        "      #Check exact match after normalization\n",
        "      if action_lower == valid_lower:\n",
        "        return valid_action\n",
        "\n",
        "      if action_lower in valid_lower or valid_lower in action_lower:\n",
        "        return valid_action\n",
        "\n",
        "      #No match\n",
        "      return action\n",
        "\n",
        "  def _intent_extraction(self, text, functions):\n",
        "    \"\"\"\n",
        "    Try to extract intent from free-form text\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    #Look for keywords that might indicate tool usage\n",
        "    for func in functions:\n",
        "      func_name = func.get('name', '')\n",
        "      func_desc = func.get('description', '').lower()\n",
        "\n",
        "      #Check if function name or key parts of description appear in text\n",
        "      if func_name.lower() in text_lower:\n",
        "        return (\n",
        "            f\"I will use the {func_name} tool.\",\n",
        "            func_name,\n",
        "            json.dumps({}) #Empty parameters as fallback\n",
        "        )\n",
        "\n",
        "      #Check for keywords from description\n",
        "      keywords = re.findall(r'\\b\\w{4,}\\b', func_desc) # Words with 4+ chars\n",
        "      for keyword in keywords[:3]:\n",
        "        if keyword in text_lower:\n",
        "          return (\n",
        "              f\"I will use the {func_name} tool.\",\n",
        "              func_name,\n",
        "              json.dumps({}) #Empty parameters as fallback\n",
        "          )\n",
        "\n",
        "      #No tool match give up\n",
        "      return (\n",
        "          text[:200] if text else \"Unable to proceed\",\n",
        "          \"Finish\",\n",
        "          json.dumps({\n",
        "              \"return_type\": \"give_up_and_restart\"\n",
        "          })\n",
        "      )\n",
        "\n",
        "\n",
        "  def get_model_name(self):\n",
        "      return \"VibeThinker-1.5B\"\n",
        "\n",
        "\n",
        "# Check dependencies first\n",
        "try:\n",
        "    import bitsandbytes as bnb\n",
        "    print(f\"✓ bitsandbytes {bnb.__version__} is installed\")\n",
        "except ImportError:\n",
        "    print(\"⚠ bitsandbytes not found, installing now...\")\n",
        "    import subprocess\n",
        "    subprocess.check_call(['pip', 'install', '-q', 'bitsandbytes'])\n",
        "    import bitsandbytes as bnb\n",
        "    print(f\"✓ bitsandbytes {bnb.__version__} installed\")\n",
        "\n",
        "# Load tokenizer\n",
        "print(\"\\nLoading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\"\n",
        "print(\"✓ Tokenizer loaded\")\n",
        "\n",
        "# Load model with 4-bit quantization\n",
        "print(\"Loading model with 4-bit quantization...\")\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=quant_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "print(\"✓ Model loaded successfully\")\n",
        "print(f\"Model device: {model.device}\")\n",
        "\n",
        "# Initialize wrapper\n",
        "llm_wrapper = VibeThinkerWrapper(model, tokenizer)\n",
        "print(\"✓ Model wrapper ready with full ToolBench interface\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YauCm3WQ1WwY",
        "outputId": "2a30ace2-e83e-4e14-dd35-c5bbb23967cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Loading VibeThinker Model\n",
            "============================================================\n",
            "✓ bitsandbytes 0.48.2 is installed\n",
            "\n",
            "Loading tokenizer...\n",
            "✓ Tokenizer loaded\n",
            "Loading model with 4-bit quantization...\n",
            "✓ Model loaded successfully\n",
            "Model device: cuda:0\n",
            "✓ Model wrapper ready with full ToolBench interface\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Quick Sanity Check\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Testing model generation...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_prompt = \"Hello! What is 2+2?\"\n",
        "print(f\"Input: {test_prompt}\")\n",
        "response = llm_wrapper.prediction(test_prompt, stop=None)\n",
        "print(f\"Output: {response}\")\n",
        "print(\"\\n✓ Model is working!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "r6Z3AyAP8GAS",
        "outputId": "44b80a6b-1d1b-416e-9f46-f5cc2a916a65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Testing model generation...\n",
            "============================================================\n",
            "Input: Hello! What is 2+2?\n",
            "Output: Let me see... I think it's 4. But wait, maybe there are other ways to add numbers that also give 4. So the answer is not unique. Hmm, but how does this relate to the expression 2 + 2?\n",
            "\n",
            "Wait a second, perhaps the question is trying to get me to consider different mathematical expressions that evaluate to the same number, even if they look different. For example, in some contexts, like modular arithmetic, 2 + 2 could be equivalent to another operation. Or maybe considering different representations of numbers.\n",
            "\n",
            "Alternatively, maybe the problem is pointing out that addition isn't just commutative or associative, but there might be different operations with the same result. Wait, but here it's the same expression. Unless we're changing the operator. Like, adding 2 and 2 gives 4, but subtracting them would give 0, multiplying gives 4 as well (if 2*2=4). Oh! Wait a minute, multiplication: 2 * 2 is also 4. So actually, both addition and multiplication can yield 4 when applied to 2 and 2. Therefore, the value 4 can come from different operations, even though the original expression was 2 + 2\n",
            "\n",
            "✓ Model is working!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup ToolBench Pipeline\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Setting up ToolBench pipeline...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from argparse import Namespace\n",
        "\n",
        "try:\n",
        "  from toolbench.inference.Downstream_tasks.rapidapi import pipeline_runner\n",
        "  print(f\"✓ Imported Toolbench modules\")\n",
        "  TOOL_ROOT_DIR = \"/content/drive/MyDrive/ToolBench_Data/toolenv/tools\"\n",
        "  print(f\"✓ Toolbench Tool Root Directory exists\")\n",
        "except Exception as e:\n",
        "  print(f\"⚠ Error importing Toolbench: {e}\")\n",
        "  print(\"You may need to adjust sys.path or check ToolBench installation.\")\n",
        "\n",
        "args = Namespace(\n",
        "    tool_root_dir=TOOL_ROOT_DIR,\n",
        "    toolbench_key=\"\",  # Empty for local simulation\n",
        "    rapidapi_key=\"\",\n",
        "    use_rapidapi_key=False,\n",
        "    api_customization=False,\n",
        "    max_observation_length=1024,\n",
        "    observ_compress_method=\"truncate\",\n",
        "    method=\"CoT@1\",\n",
        "    input_query_file=\"\",  # Will be set per test set\n",
        "    output_answer_file=OUTPUT_DIR,\n",
        "    backbone_model=llm_wrapper,\n",
        "    openai_key=\"\",\n",
        "    max_sequence_length=8192,\n",
        "    max_source_sequence_length=2048,\n",
        "    lora=False,\n",
        "    model_path=\"\",\n",
        "    lora_path=\"\",\n",
        "    corpus_tsv_path=\"\",\n",
        "    retrieval_model_path=\"\"\n",
        ")\n",
        "\n",
        "print(f\"✓ Pipeline Configured\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kebgX82bBDKY",
        "outputId": "09ec5d52-43fd-46a3-9737-5f541c7cc354"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Setting up ToolBench pipeline...\n",
            "============================================================\n",
            "✓ Imported Toolbench modules\n",
            "✓ Toolbench Tool Root Directory exists\n",
            "✓ Pipeline Configured\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Diagnostic Cell -> Tool Presence\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DIAGNOSTIC: Checking Tool Setup\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check the tool directory\n",
        "TOOL_ROOT_DIR = \"/content/drive/MyDrive/ToolBench_Data/toolenv/tools\"\n",
        "print(f\"\\nTool directory: {TOOL_ROOT_DIR}\")\n",
        "print(f\"Exists: {os.path.exists(TOOL_ROOT_DIR)}\")\n",
        "\n",
        "if os.path.exists(TOOL_ROOT_DIR):\n",
        "    # List categories\n",
        "    categories = [d for d in os.listdir(TOOL_ROOT_DIR) if os.path.isdir(os.path.join(TOOL_ROOT_DIR, d))]\n",
        "    print(f\"\\nFound {len(categories)} categories:\")\n",
        "\n",
        "    total_tools = 0\n",
        "    for cat in categories[:5]:  # Show first 5\n",
        "        tools = [f for f in os.listdir(os.path.join(TOOL_ROOT_DIR, cat)) if f.endswith('.json')]\n",
        "        print(f\"  - {cat}: {len(tools)} tools\")\n",
        "        total_tools += len(tools)\n",
        "\n",
        "    if len(categories) > 5:\n",
        "        print(f\"  ... and {len(categories) - 5} more categories\")\n",
        "\n",
        "    print(f\"\\nTotal tools found: {total_tools}\")\n",
        "\n",
        "    # Show a sample tool\n",
        "    if categories:\n",
        "        sample_cat = categories[0]\n",
        "        sample_tools = [f for f in os.listdir(os.path.join(TOOL_ROOT_DIR, sample_cat)) if f.endswith('.json')]\n",
        "        if sample_tools:\n",
        "            sample_file = os.path.join(TOOL_ROOT_DIR, sample_cat, sample_tools[0])\n",
        "            print(f\"\\nSample tool file: {sample_file}\")\n",
        "            with open(sample_file) as f:\n",
        "                tool_data = json.load(f)\n",
        "                print(f\"Tool name: {tool_data.get('tool_name', 'N/A')}\")\n",
        "                print(f\"APIs: {len(tool_data.get('api_list', []))}\")\n",
        "else:\n",
        "    print(\"\\n❌ Tool directory does not exist!\")\n",
        "    print(\"\\nYou need to upload your tool definitions.\")\n",
        "\n",
        "# Check a sample query to see what tools it expects\n",
        "TEST_DATA_DIR = \"/content/drive/MyDrive/ToolBench_Data/test_instruction\"\n",
        "sample_query_file = os.path.join(TEST_DATA_DIR, \"G1_instruction.json\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Checking Query Expectations\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if os.path.exists(sample_query_file):\n",
        "    with open(sample_query_file) as f:\n",
        "        queries = json.load(f)\n",
        "\n",
        "    print(f\"\\nSample query from G1_instruction:\")\n",
        "    sample = queries[0]\n",
        "    print(f\"Query: {sample.get('query', 'N/A')[:100]}...\")\n",
        "\n",
        "    if 'api_list' in sample:\n",
        "        print(f\"\\nExpected tools:\")\n",
        "        for api in sample['api_list'][:3]:\n",
        "            print(f\"  - Category: {api.get('category_name', 'N/A')}\")\n",
        "            print(f\"    Tool: {api.get('tool_name', 'N/A')}\")\n",
        "            print(f\"    API: {api.get('api_name', 'N/A')}\")\n",
        "            print()\n",
        "else:\n",
        "    print(f\"\\n❌ Query file not found: {sample_query_file}\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akwoPQiNZiuR",
        "outputId": "e995ae38-0215-4110-d0ae-eb5543e9330b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DIAGNOSTIC: Checking Tool Setup\n",
            "============================================================\n",
            "\n",
            "Tool directory: /content/drive/MyDrive/ToolBench_Data/toolenv/tools\n",
            "Exists: True\n",
            "\n",
            "Found 50 categories:\n",
            "  - Business: 695 tools\n",
            "  - Artificial_Intelligence_Machine_Learning: 390 tools\n",
            "  - Advertising: 158 tools\n",
            "  - Business_Software: 350 tools\n",
            "  - Customized: 1 tools\n",
            "  ... and 45 more categories\n",
            "\n",
            "Total tools found: 1594\n",
            "\n",
            "Sample tool file: /content/drive/MyDrive/ToolBench_Data/toolenv/tools/Business/israel_company_data.json\n",
            "Tool name: Israel Company Data\n",
            "APIs: 1\n",
            "\n",
            "============================================================\n",
            "Checking Query Expectations\n",
            "============================================================\n",
            "\n",
            "Sample query from G1_instruction:\n",
            "Query: I am a fitness enthusiast and I want to buy a fitness tracker. Can you suggest some top-rated fitnes...\n",
            "\n",
            "Expected tools:\n",
            "  - Category: Data\n",
            "    Tool: ASIN Data\n",
            "    API: Category\n",
            "\n",
            "  - Category: Data\n",
            "    Tool: ASIN Data\n",
            "    API: Offers\n",
            "\n",
            "  - Category: Data\n",
            "    Tool: ASIN Data\n",
            "    API: Reviews\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run evaluation:\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Starting evaluation...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "test_sets = [\"G1_instruction\", \"G1_category\", \"G1_tool\", \"G2_category\", \"G2_instruction\", \"G3_instruction\"]\n",
        "\n",
        "results_summary = {}\n",
        "\n",
        "for subset in test_sets:\n",
        "  input_file = os.path.join(TEST_DATA_DIR, f'{subset}.json')\n",
        "\n",
        "  if not os.path.exists(input_file):\n",
        "    print(f\"⚠ Skipping evaluation for subset: {subset}. Test data not found.\")\n",
        "    results_summary[subset] = \"File not found\"\n",
        "    continue\n",
        "\n",
        "  with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    queries = json.load(f)\n",
        "    print(f\"Found {len(queries)} queries in {subset}\")\n",
        "\n",
        "  args.input_query_file =  input_file\n",
        "  args.output_answer_file = os.path.join(OUTPUT_DIR, subset)\n",
        "\n",
        "  try:\n",
        "    runner = pipeline_runner(\n",
        "        args=args,\n",
        "        add_retrieval=False,\n",
        "        process_id=0,\n",
        "        server=False\n",
        "    )\n",
        "\n",
        "    runner.run()\n",
        "    print(f\"✓ Completed {subset}\")\n",
        "    results_summary[subset] = \"Success\"\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"✗ Error running evaluation for subset: {subset}. Error: {e}\")\n",
        "    results_summary[subset] = f\"Error: {str(e)}\"\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VyMXHp0c6FUx",
        "outputId": "7d66c7d5-e5ee-4195-f9bc-8b94210be94d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Starting evaluation...\n",
            "============================================================\n",
            "Found 200 queries in G1_instruction\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [01:15<00:00,  1.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total tasks: 200\n",
            "undo tasks: 178\n",
            "process[0] doing task 0/178: real_task_id_17038\n",
            "[process(0)]now playing Can you please provide a list of available telephone numbers for the country 'Canada' using the List available numbers for a country API? I also need to retrieve the audio file from a text-to-speech conversion with the transaction ID '13579' using the Retrieve audio file API., with 7 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: 1. Think: I am in the country for the country for the country for the country for the country for the country for the country for the country for the country for the country for the country for the co\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 1/178: real_task_id_55489\n",
            "[process(0)]now playing I need to gather information about the crime rates and accidents in Germany. Please fetch all the news articles related to police activities from various sources like tag24. Also, provide me with the title, URL, and source of each article., with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I need to find the news for the crime rate and the other from the tag24.\n",
            "       I need to find the news for the crime rate and the other from the tag24.\n",
            "       I need to find the news for the crime ra\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 2/178: real_task_id_81581\n",
            "get_username_pubg_mobile ['GET username Haki Chat', 'GET username Tumile', 'GET username Poppo Live', 'GET username LivU', 'GET username Likee', 'GET username 4Fun', 'GET username YoYo Chat', 'GET username Mico Live', 'GET username Bigo Live', 'GET username Azal Live', 'GET username SoulFa Chat', 'GET username Binmo Chat', 'GET username Hawa Chat', 'GET username Hiya Chat', 'GET username Oohla Chat', 'GET username MixU', 'GET username Ahlan Chat', 'GET username Soulchill', 'GET username Nimo TV', 'GET username Free Fire Indonesia', 'GET username Free Fire Global (slow)', 'GET username PUBGM Global', 'GET username Point Blank', 'GET username Genshin Impact', 'GET username Higgs Domino', 'GET username Arena of Valor', 'GET username Mobile Legends', 'GET username Jawaker', 'GET username Call of Duty Mobile', 'GET username Valorant']\n",
            "get_username_free_fire ['GET username Haki Chat', 'GET username Tumile', 'GET username Poppo Live', 'GET username LivU', 'GET username Likee', 'GET username 4Fun', 'GET username YoYo Chat', 'GET username Mico Live', 'GET username Bigo Live', 'GET username Azal Live', 'GET username SoulFa Chat', 'GET username Binmo Chat', 'GET username Hawa Chat', 'GET username Hiya Chat', 'GET username Oohla Chat', 'GET username MixU', 'GET username Ahlan Chat', 'GET username Soulchill', 'GET username Nimo TV', 'GET username Free Fire Indonesia', 'GET username Free Fire Global (slow)', 'GET username PUBGM Global', 'GET username Point Blank', 'GET username Genshin Impact', 'GET username Higgs Domino', 'GET username Arena of Valor', 'GET username Mobile Legends', 'GET username Jawaker', 'GET username Call of Duty Mobile', 'GET username Valorant']\n",
            "[process(0)]now playing I would like to inquire about the username for my Mobile Legends ID '1393323764' on server '15748'. Can you help me find the username using the GET username Mobile Legends API? Additionally, I want to verify the username for my Valorant Riot ID 'ucup' and tag '123' using the GET username Valorant API., with 8 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: 1. Get the first sentence:\n",
            "           Thought: [one sentence] → [one]\n",
            "\n",
            "           Assimilillillillillillillillillillillillillillillillillillillillillillillillillillillillillillillillillillillillillill\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 3/178: real_task_id_71402\n",
            "[process(0)]now playing I am concerned about the vulnerabilities in industrial control systems. Can you provide advisories related to Siemens using the Get Advisories By Vendor API? It would be great if I could limit the number of advisories to 2 and include additional information in the response. Additionally, I need a list of all advisories using the Get All Advisories API., with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I am concerned about the exa m t c s f g h l o n d e v u p l o p i n d a v u p l o w a v u p l o w a v u p l o w a v u p l o w a v u p l o w a v u p l o w a v u p l o w a v u p l o w a v u p l o w a v\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 4/178: real_task_id_20628\n",
            "[process(0)]now playing I am planning a trip to Tokyo and I want to explore the dynamic hotel options available there. Can you provide me with a list of hotels in Tokyo that offer unique experiences, such as capsule hotels, traditional ryokans, and themed hotels? It would be helpful to know the availability and prices of these hotels., with 5 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 257\n",
            "Thought: Thoughts: I need to search for available flights between I and j. But also I and j. So no. Or action. or price. or . but i and j. or not. or action. or. or. or. or. or. or. or. or. or. or. or. or. or.\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 5/178: real_task_id_45490\n",
            "[process(0)]now playing I'm a cryptocurrency trader and I need real-time data on the most mentioned coins and their sentiment. Can you retrieve the top coins by mentions and their mentions value? Additionally, fetch the top coins by sentiment change in the last 24 hours., with 11 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: donoc \\n\\t\\ \\n\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 6/178: real_task_id_1856\n",
            "[process(0)]now playing I'm planning to place some bets on today's soccer matches. Can you provide me with the best goal prediction, the best 2 sign prediction, and the best 1 sign prediction? Additionally, I would like to know if there are any good odds available for betting. Please include the country name, league name, team names, bet, bet quote, and match date in the response., with 8 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 253\n",
            "Thought: 1. The Assistant will think about the problem. The problem is the equation. The equation is the same. The equation is the same. The equation is the same. The equation is the same. The equation is the \n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 7/178: real_task_id_85152\n",
            "[process(0)]now playing I am working on a research project, and I need data about a specific item from 'Ebay de Product Details Page Scraper'. Can you help me retrieve all the details for ITEM_ID '265488616472'? I require information such as the product description, seller location, and shipping options., with 2 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I am working on a research project, and I need data about a product description, seller location, and shipping options.\n",
            "       I am working on a research project, and I need data about a product descr\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 8/178: real_task_id_13095\n",
            "[process(0)]now playing I want to know the list of categories available in the advertising tool. Also, get the product details for the products in the 'Electronics' category., with 6 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 238\n",
            "Thought: I will use the get_products_in_category_for_asdfadsf tool.\n",
            "Action: get_products_in_category_for_asdfadsf\n",
            "query to Advertising-->asdfadsf-->get_products_in_category_for_asdfadsf\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 256\n",
            "Thought: ASISTAN:\n",
            "       ASISTAN:\n",
            "       ASISTAN:\n",
            "       ASISTAN:\n",
            "       ASISTAN:\n",
            "       ASISTAN:\n",
            "       ASISTAN:\n",
            "       ASISTAN:\n",
            "       ASISTAN:\n",
            "       ASISTAN:\n",
            "       ASISTAN:\n",
            "       ASISTAN:\n",
            "       ASISTAN:\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 9/178: real_task_id_52734\n",
            "[process(0)]now playing I am an avid football fan who enjoys betting on matches. Can you help me by providing the active Premium Tips using the Betigolo Tips API? Additionally, I would like to review the historical results of the Premium Tips in the past 30 days to assess their accuracy. Please include the match date, sport, country, league, home team, away team, tip, fair odd, tip odd, result, tip success, and tip profit in the response., with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I am an. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 10/178: real_task_id_3308\n",
            "[process(0)]now playing I'm organizing a track and field event and I need to calculate the points for the women's high jump. Can you provide me with the marks required for different point values, such as 1000, 1100, and 1200? Additionally, I would like to retrieve the men's marks for the same point values., with 5 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I need to search for available flights between London and Dubai. How many? I have. I have. I have. I am. I am. I am. I am. I am. I am. I am. I am. I am. I am. I am. I am. I am. I am. I am. I am. I am.\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 11/178: real_task_id_12204\n",
            "[process(0)]now playing I am a travel blogger and I want to provide my readers with information on different types of airplanes. Can you provide me with a list of all the airplanes ordered by their names in descending order, along with their passenger capacity and range?, with 8 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 254\n",
            "Thought: ASSISTANT\n",
            "       ASSISTANT\n",
            "       ASISTANT\n",
            "     ASISTANT\n",
            "     ASistant\n",
            "     Asistent\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "   \n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 12/178: real_task_id_67007\n",
            "sms_mt_send_sms_get ['Get delivery status', 'SMS-MT - Send SMS (POST)']\n",
            "[process(0)]now playing I would like to send an SMS to my friend +11112222333. The message should say 'Congratulations on your promotion!'. Additionally, I need to schedule this message to be sent next week. Can you please confirm the delivery status of this message using the unique message ID?, with 2 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 253\n",
            "Thought: I would like to send an SMS to my friend +111222333. The message says 'Congon' or 'Congon'.\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_answer\", \"final_answer\": \"the solution.\\n    6. The answer is the solution.\\n    7. The answer is the solution.\\n    8. The answer is the solution.\\n    9. The answer is the solution.\\n    10. The answer is the solution.\\n    11. The answer is the solution.\"}\n",
            "Observation: {\"response\":\"successfully giving the final answer.\"}\n",
            "[process(0)]valid=True\n",
            "process[0] doing task 13/178: real_task_id_31117\n",
            "[process(0)]now playing Can you help me find a college in Cairo? I am looking for the address, latitude, and longitude of the college. Please limit the results to 5., with 6 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 171\n",
            "Thought: 1.   think:   #  #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #   #  \n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 14/178: real_task_id_26752\n",
            "[process(0)]now playing I'm a small business owner looking to invest in the stock market. I want to make informed decisions based on the probability of price movements and peer ratios. Can you give me the probability of the stock price going up or down in the next day, week, and month, as well as the average peer ratios for Apple Inc.?, with 7 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: 1. Think: I am an ex on the ex. But I am not on the ex. But I am not on the ex. So I am not on the ex. But I am not on the ex. But I am not on the ex. But I am not on the ex. But I am not on the ex. B\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 15/178: real_task_id_86084\n",
            "[process(0)]now playing Please search the web for reviews and opinions about the latest smartphone model. We need to gather insights and feedback from users to improve our product. Use the keyword 'latest smartphone model' for the search. Thank you., with 2 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: User: [impossible request] -> ASSISTANT: I need to find a task in L, which is, and then action input origin, destination, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , \n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 16/178: real_task_id_10160\n",
            "[process(0)]now playing As an online retailer, I want to offer a wide range of products to my customers. Can you provide me with a list of products in the '100003819' category? I would like to filter the products by brand, attributes, and price range. Additionally, I need the feedback from customers who have purchased these products, including their feedback content, ratings, and photos. Thank you!, with 11 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the api_product_productid_feedbacks_for_magic_aliexpress tool.\n",
            "Action: api_product_productid_feedbacks_for_magic_aliexpress\n",
            "query to eCommerce-->magic_aliexpress-->api_product_productid_feedbacks_for_magic_aliexpress\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the api_product_productid_feedbacks_for_magic_aliexpress tool.\n",
            "Action: api_product_productid_feedbacks_for_magic_aliexpress\n",
            "query to eCommerce-->magic_aliexpress-->api_product_productid_feedbacks_for_magic_aliexpress\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the api_product_productid_feedbacks_for_magic_aliexpress tool.\n",
            "Action: api_product_productid_feedbacks_for_magic_aliexpress\n",
            "query to eCommerce-->magic_aliexpress-->api_product_productid_feedbacks_for_magic_aliexpress\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the api_product_productid_feedbacks_for_magic_aliexpress tool.\n",
            "Action: api_product_productid_feedbacks_for_magic_aliexpress\n",
            "query to eCommerce-->magic_aliexpress-->api_product_productid_feedbacks_for_magic_aliexpress\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 17/178: real_task_id_75338\n",
            "[process(0)]now playing I'm organizing a party and need some upbeat songs to create a playlist. Can you suggest some trending songs and artists? I would like to include the top songs and videos from different genres. Please provide me with a list of trending music., with 11 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 254\n",
            "Thought: apidetailed, get_lyricsForYoutubeMusicD, get_LyricsForYuttonMusicD, get_LyricsForYountiM di, get_LyricsForYoutiM di, get_LyricsForYoutiM di, get_LyricsForYoutiM di, get_LyricsForYoutiM di, get_LyricsF\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 18/178: real_task_id_74814\n",
            "[process(0)]now playing I am a football enthusiast and I want to stay updated on all the live matches happening around the world. Can you provide me with the live streaming link for the next major football event?, with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I am a football event and I am a football event and I am a football event and I am a football event and I am a football event and I am a football event and I am a football event and I am a football ev\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 19/178: real_task_id_26063\n",
            "[process(0)]now playing I am an HR manager looking to expand my talent pool. Can you retrieve the available job titles for 'human resources' and the available locations in 'Chicago'? Additionally, fetch a list of companies related to 'manufacturing'., with 4 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 254\n",
            "Thought: 1. Think: I need to find a way to the task. I'm going to the task. I'm going to the exa.\n",
            "       2. Imagine: I'm going to the task. I'm going to the exa.\n",
            "       3. Feel: I'm going to the task. I'm goin\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 20/178: real_task_id_2399\n",
            "[process(0)]now playing I want to know the details of the game with ID 12345. Give me the date, home team, home team score, visitor team, and visitor team score. Additionally, provide the player statistics for this game., with 8 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: 1. Think: I am going to the game.\n",
            "        2. Action: Get into the specific team.\n",
            "        3. Action: Get into the specific team.\n",
            "        4. Action: Get into the specific team.\n",
            "        5. Action: Get in\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 21/178: real_task_id_62012\n",
            "[process(0)]now playing I want to analyze the income statement and the balance sheet of Apple (AAPL) for the last quarter. Additionally, I need the current composition of executives and the amount of current shares float., with 11 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: 1.   ASSISTANT RESPONSE: 1.   ASSISTAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 22/178: real_task_id_70610\n",
            "[process(0)]now playing My friend is interested in investing in stocks and wants to know more about Google. Can you fetch the quarterly cash flow, balance sheet, income statement, and ratios for Google? It would be great to have data on net income, total assets, revenue, and current ratio to assess the company's financial health., with 10 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: ASSISTANT\n",
            "       AS\n",
            "     [one sentence]\n",
            "\n",
            "     Example:\n",
            "\n",
            "     [After the long thought:]\n",
            "\n",
            "     Thought: I have received the EXA-TO-AND-RIS-HEL-L-S-T-TH-NEG-EX-A-B-C-D-E-F-L-S-T-H-N-G-C-D-C-C-P-S-N-C-B-Z\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 23/178: real_task_id_22937\n",
            "[process(0)]now playing I'm a content creator working on a project about happiness. Can you provide me with quotes about happiness with a maximum character count of 100? Additionally, could you give me quotes from different sources like Aristotle, Dalai Lama, and Albert Einstein?, with 5 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: [Thought] = I am in [thought] = I am in [thought] = I am in [thought] = I am in [thought] = I am in [thought] = I am in [thought] = I am in [thought] = I am in [thought] = I am in [thought] = I am in \n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 24/178: real_task_id_55323\n",
            "[process(0)]now playing I'm working on a research paper about climate change and I need a comprehensive list of all the climate change news articles available. Can you fetch those for me? I also require articles specifically from The Guardian. Additionally, it would be helpful if you can provide me with the API's home page for further reference., with 4 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: Assist: I need to find the climate change news articles from the climate change live v222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 25/178: real_task_id_44482\n",
            "[process(0)]now playing I am planning to watch a live sports event. Can you provide me with a list of upcoming fixtures for a specific sport? Additionally, I would like to know the in-play events and their scores, stats, and markets. Finally, can you give me the pre-match odds for a particular event?, with 7 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: I will use the bet365_inplay_filter_for_betsapi tool.\n",
            "Action: bet365_inplay_filter_for_betsapi\n",
            "query to Sports-->betsapi-->bet365_inplay_filter_for_betsapi\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 256\n",
            "Thought: USER: [imply] the bet365_inplay_data for the event.\n",
            "       ASSISTANT:\n",
            "         Thought: I need to search for available flights between London and Dubai.\n",
            "         Action: search_flights\n",
            "         Though\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 26/178: real_task_id_32285\n",
            "[process(0)]now playing I'm writing a comedy script and I need a large collection of jokes. Can you give me a list of jokes with a limit of 200 and sorted by score in descending order? Also, provide me with the joke of the day and the available categories of jokes., with 8 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 254\n",
            "Thought: 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 27/178: real_task_id_47195\n",
            "[process(0)]now playing I'm working on a research project about social media trends in different countries. Could you fetch the social media news in Russian, Portuguese, Dutch, and Italian? I need the latest news articles to analyze the trends., with 11 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 254\n",
            "Thought: 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 28/178: real_task_id_44238\n",
            "[process(0)]now playing I am a baseball enthusiast and want to stay updated on the latest news and breaking updates in the MLB. Can you provide me with real-time news articles, including headlines, summaries, and publication dates? It would be helpful to have the small images of the news sources and the large images of the featured athletes mentioned in the articles., with 11 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 251\n",
            "Thought: I will use the competitor_small_image_for_allscores tool.\n",
            "Action: competitor_small_image_for_allscores\n",
            "query to Sports-->allscores-->competitor_small_image_for_allscores\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the competitor_small_image_for_allscores tool.\n",
            "Action: competitor_small_image_for_allscores\n",
            "query to Sports-->allscores-->competitor_small_image_for_allscores\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the competitor_small_image_for_allscores tool.\n",
            "Action: competitor_small_image_for_allscores\n",
            "query to Sports-->allscores-->competitor_small_image_for_allscores\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 255\n",
            "Thought: I will use the competitor_small_image_for_allscores tool.\n",
            "Action: competitor_small_image_for_allscores\n",
            "query to Sports-->allscores-->competitor_small_image_for_allscores\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 29/178: real_task_id_40699\n",
            "[process(0)]now playing I'm a fitness trainer and I want to create a workout routine based on impressive Guinness World Records related to push-ups. Can you fetch the record details for the most challenging push-up records, including who achieved them, where and when they took place, and any tips or techniques used to accomplish these records?, with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I'm a fitness trainer and I want to create a workout routine based on impressive Guinness World records related to push-ups. I'm a fitness trainer and I want to create a workout routine based on impre\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 30/178: real_task_id_43269\n",
            "[process(0)]now playing I'm an aspiring photographer and I'm looking for inspiration for my next photo project. Can you provide me with a list of interests related to photography and visual arts? Additionally, I would like to explore different countries and their iconic landmarks., with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I'm an asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp of a asp \n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 31/178: real_task_id_62568\n",
            "[process(0)]now playing I'm planning to add a new post in a specific language. Can you fetch me the details of a language with the ID 5? I would also like to get a paginated list of all posts and the scores associated with each post., with 7 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 254\n",
            "Thought: 1.  (7 total)\n",
            "       2.   (7 total)\n",
            "       3.   (7 total)\n",
            "       4.   (7 total)\n",
            "       5.   (7 total)\n",
            "       6.   (7 total)\n",
            "       7.   (7 total)\n",
            "       8.   (7 total)\n",
            "       9.   (7 total)\n",
            "       10.\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 32/178: real_task_id_17087\n",
            "[process(0)]now playing I'm a developer working on a news aggregator app. Can you provide me with the full-text articles, images, and author information for the top news articles from various news sources? It would be helpful to sort the articles by category and include the publication date., with 4 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: 1. The user says: I am to write for the book in the science of the book. The user say: I am to write for the book. The user say: I am to write for the book. The user say: I am to write for the book. T\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 33/178: real_task_id_577\n",
            "[process(0)]now playing I am a fitness enthusiast and I want to buy a fitness tracker. Can you suggest some top-rated fitness trackers available on Amazon along with their features and prices?, with 6 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: I will use the category_for_asin_data tool.\n",
            "Action: category_for_asin_data\n",
            "query to Data-->asin_data-->category_for_asin_data\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 210\n",
            "Thought: I will use the category_for_asin_data tool.\n",
            "Action: category_for_asin_data\n",
            "query to Data-->asin_data-->category_for_asin_data\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 254\n",
            "Thought: I will use the category_for_asin_data tool.\n",
            "Action: category_for_asin_data\n",
            "query to Data-->asin_data-->category_for_asin_data\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 255\n",
            "Thought: I will use the category_for_asin_data tool.\n",
            "Action: category_for_asin_data\n",
            "query to Data-->asin_data-->category_for_asin_data\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 34/178: real_task_id_70915\n",
            "[process(0)]now playing I am a travel blogger and would like to explore new destinations. Can you suggest some cities where Flixbus operates? I am particularly interested in cities with historical landmarks and natural attractions. Also, provide me with the available trips and schedules for each city., with 6 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 253\n",
            "Thought: 1. Always choose the way for the EXACT format.\n",
            "Action: stations_for_flixbus\n",
            "query to Travel-->flixbus-->stations_for_flixbus\n",
            "Action Input: {\"param\": \"value\"}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 255\n",
            "Thought: 1. always choose the way for the exa m e n t a r e s . a r e s . a r e s . a r e s . a r e s . a r e s . a r e s . a r e s . a r e s . a r e s . a r e s . a r e s . a r e s . a r e s . a r e s . a r e\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 35/178: real_task_id_84845\n",
            "[process(0)]now playing Help me find the issuer card information by entering the first 6 digits of a credit/debit card using the BIN/IIN Lookup API. I would like to know the details for a card with the BIN '470886'., with 2 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I need to find the bin i n k m . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 36/178: real_task_id_4505\n",
            "[process(0)]now playing I'm helping my friend with their language studies, and we need assistance with spelling out numbers in different languages. Can you provide a list of languages supported by the Spellout API? Additionally, we would like to know the available rule sets for each language. Finally, it would be great if you could spell out the number 123 in multiple languages using the appropriate rule sets., with 4 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: 1. User wants to say: I need to find a number. But the number is not. Or the number is. Or the number is. or the number is. or the number is. or the number is. or the number is. or the number is. or t\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 37/178: real_task_id_33330\n",
            "[process(0)]now playing As a video editor, I want to check the progress of my video upload. Can you fetch the ingest job status for the video with the ID '99999' in my account? Also, generate temporary upload URLs for the video from the source 'original' in my account., with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: AS the video with the ID '99999', I want to check the progress of my video upload. Can you fetch the ingest job status for the video?\n",
            "\n",
            "       ASSISTANT:\n",
            "       User: [impossible request] -> [user: imp\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 38/178: real_task_id_42802\n",
            "[process(0)]now playing I'm looking for a reliable plumber in my area to fix a leaky faucet. Can you recommend any plumbers near me with their contact details and customer reviews? It would be helpful if you can also provide the working hours of the plumbers so that I can schedule an appointment., with 8 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the business_reviews_for_local_business_data tool.\n",
            "Action: business_reviews_for_local_business_data\n",
            "query to Data-->local_business_data-->business_reviews_for_local_business_data\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the business_reviews_for_local_business_data tool.\n",
            "Action: business_reviews_for_local_business_data\n",
            "query to Data-->local_business_data-->business_reviews_for_local_business_data\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the business_reviews_for_local_business_data tool.\n",
            "Action: business_reviews_for_local_business_data\n",
            "query to Data-->local_business_data-->business_reviews_for_local_business_data\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the business_reviews_for_local_business_data tool.\n",
            "Action: business_reviews_for_local_business_data\n",
            "query to Data-->local_business_data-->business_reviews_for_local_business_data\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 39/178: real_task_id_14714\n",
            "[process(0)]now playing I'm planning a trip to Europe and I want to stay updated with the latest hashtags worldwide. Can you provide me with a list of recent trending hashtags globally? Additionally, could you suggest popular hashtags specific to Argentina? It would be great if you could include the volume of tweets and links related to each hashtag., with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I'm planning a trip to Europe and I want to stay update with the latest hashtags worldwide. I am am planning a trip to Europe and i want to stay update with the latest hashtags worldwide. I am am plan\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 40/178: real_task_id_68221\n",
            "[process(0)]now playing I'm a blogger and I want to optimize my website for better search engine rankings. Can you analyze the SEO metrics for my blog's domain 'myblogwebsite.com' and suggest some high-performing keywords?, with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I need to find the company's email. But there's no. \n",
            "\n",
            "     [After getting the answer]\n",
            "\n",
            "     I need to find the company's email. But there's no. \n",
            "\n",
            "     [But then getting the answer]\n",
            "\n",
            "     I need to fin\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 41/178: real_task_id_77471\n",
            "[process(0)]now playing Can you help me find popular videos and trending gaming videos? I'm interested in their titles, authors, view counts, and thumbnails. I'm using the 'Cheap YouTube API' tool., with 9 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: 1. Search for popular videos and trends:\n",
            "           Action: [search for popular videos and trends]\n",
            "           Des: [des] [ [ [ [ [ | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 42/178: real_task_id_59266\n",
            "[process(0)]now playing I am planning a surprise party for my sister's graduation. Can you help me with the guest list? I would like to retrieve a list of users from the Reqres tool and get their names and email addresses. Additionally, I need to check if there are any unknown resources available that I can use for party decorations., with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I am planning a surprise party for my sister's graduation. I am planning a surprise party for my sister's graduation. I am planning a surprise party for my sister's graduation. I am planning a surpris\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 43/178: real_task_id_32970\n",
            "[process(0)]now playing I'm a music researcher and I'm looking for data on the most viewed YouTube music videos of all time. Can you give me the top viewed videos for each year from 2007 to the present? Additionally, I would like to know the number of views, likes, and comments for each video., with 11 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 33\n",
            "Thought: ASSISTANT: [one sentence]  \n",
            "       ACTION: [one sentence]  \n",
            "       DESCRIPTION:  \n",
            "\n",
            "       But the but the **********************************************************************************************\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 44/178: real_task_id_47838\n",
            "[process(0)]now playing I want to see the summoner profile for the player with the summoner name 'Nogaruki' in League of Legends. Additionally, provide me with their recent match history and a list of free champion rotations., with 8 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 252\n",
            "Thought: 1. Start: Assist in the second action.\n",
            "       2. Choose: Assume the second action.\n",
            "       2. Choose: Assuming the second action.\n",
            "       2. Choose: Assuming the second action.\n",
            "       2. Choose: Assumin\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 45/178: real_task_id_5815\n",
            "[process(0)]now playing I'm a journalist writing an article about different states in the US. Can you provide me with a list of states and their abbreviations? Also, suggest some famous landmarks in each state., with 10 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: ┻━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 46/178: real_task_id_3723\n",
            "[process(0)]now playing I'm planning to surprise my mom with a house plant for her birthday. Can you suggest a flowering plant that can add a pop of color to her living room? It would be helpful if you could provide information about its ideal light conditions and any common diseases it might be prone to., with 7 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: ASSISTANT: [thought: I am not or or or or . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 47/178: real_task_id_77514\n",
            "[process(0)]now playing I'm a film student doing research on videos with the tag 'animation'. Can you provide me with videos that have this tag? I would like to see the most commented videos first., with 11 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 257\n",
            "Thought: I will use the getrelatedchannels_for_vimeo tool.\n",
            "Action: getrelatedchannels_for_vimeo\n",
            "query to Media-->vimeo-->getrelatedchannels_for_vimeo\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 249\n",
            "Thought: I will use the getrelatedchannels_for_vimeo tool.\n",
            "Action: getrelatedchannels_for_vimeo\n",
            "query to Media-->vimeo-->getrelatedchannels_for_vimeo\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 254\n",
            "Thought: I will use the getrelatedchannels_for_vimeo tool.\n",
            "Action: getrelatedchannels_for_vimeo\n",
            "query to Media-->vimeo-->getrelatedchannels_for_vimeo\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the getrelatedchannels_for_vimeo tool.\n",
            "Action: getrelatedchannels_for_vimeo\n",
            "query to Media-->vimeo-->getrelatedchannels_for_vimeo\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 48/178: real_task_id_62757\n",
            "[process(0)]now playing I'm planning a trip to New York and I want to know the search engine results for the query 'best attractions in New York'. Can you create a task to retrieve the complete SERP data for this query? Once the task is completed, please provide me with the task ID so that I can use it to obtain the results using the 'GetTaskResult' endpoint. Additionally, I would like to specify the language as English and the region as New York., with 6 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 252\n",
            "Thought: 1. Get the task id for the following:\n",
            "           - Task id for the following:\n",
            "             - Task id for the following:\n",
            "               - Task id for the following:\n",
            "                 - Task id for the f\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 49/178: real_task_id_77901\n",
            "[process(0)]now playing I am a sports journalist and I need the game information for all NBA games on a specific date. Can you provide me with the game schedule, including the teams playing, game dates, and start times? Also, give me the betting odds for the games, including the spreads, over/under, and moneyline., with 11 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: I will use the nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats tool.\n",
            "Action: nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats\n",
            "query to Sports-->tank01_fantasy_stats-->nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 146\n",
            "Thought: I will use the nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats tool.\n",
            "Action: nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats\n",
            "query to Sports-->tank01_fantasy_stats-->nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 255\n",
            "Thought: I will use the nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats tool.\n",
            "Action: nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats\n",
            "query to Sports-->tank01_fantasy_stats-->nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 255\n",
            "Thought: I will use the nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats tool.\n",
            "Action: nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats\n",
            "query to Sports-->tank01_fantasy_stats-->nba_games_and_stats_for_a_single_player_for_tank01_fantasy_stats\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 50/178: real_task_id_28751\n",
            "[process(0)]now playing I'm a financial analyst working on a report about SPACs and I need the latest SEC filings for a specific SPAC. Can you provide me with the ticker symbol, form type, form description, filing date, and document link? Additionally, I'm interested in the latest price targets from analysts for another SPAC., with 7 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 253\n",
            "Thought: 1. Tell:  \n",
            "        action = \"spiral top 10 gainer 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 \n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 51/178: real_task_id_34823\n",
            "[process(0)]now playing As a customer, I want to explore the catalog and find products in a specific category. Can you provide me with the list of products in the 'Video_Images' category? Additionally, give me the details of a specific product with the ID '1234'., with 8 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: I will use the get_product_for_demo_project_v2 tool.\n",
            "Action: get_product_for_demo_project_v2\n",
            "query to Video_Images-->demo_project_v2-->get_product_for_demo_project_v2\n",
            "Action Input: {}\n",
            "Observation: {\"error\": \"Unauthorized error...\", \"response\": \"You are not authorized for our rapidapi service. Please fill out our application form and we will process it as soon as possible.\"}\n",
            "[process(0)]total tokens: 253\n",
            "Thought: 1. ACTION: [one sentence] -> [eight sentences]\n",
            "\n",
            "       1. ACTION: [one sentence] -> [ eight sentences ]\n",
            "\n",
            "     1. ACTION: [one sentence] -> [ eight sentences ]\n",
            "\n",
            "     1. ACTION: [one sentence] -> [ eigh\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 52/178: real_task_id_72659\n",
            "[process(0)]now playing I'm writing a blog post about my favorite books and I want to include the book cover images. Can you provide me with the book cover URLs and images for the ISBNs 9781526606198, 9780062982654, and 9780142424179? It would be great if the language code is set to English., with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: 1. I need to write the book cover image URL and name. So I can write the book cover image URL and name. So I can write the book cover image URL and name. So I can write the book cover image URL and na\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 53/178: real_task_id_17952\n",
            "[process(0)]now playing I'm interested in the COVID-19 situation in India. Can you provide me with the latest updates on active, recovered, and deaths cases in the country? Additionally, I would like to know the guidelines and bills related to the coronavirus. Please organize this information into a comprehensive report., with 4 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: ASSISTANT:\n",
            "       AS\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "     A\n",
            "    \n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 54/178: real_task_id_43821\n",
            "[process(0)]now playing I need information on the latest Macbook Air for my family member. Can you fetch the search results for this product, including the product details, prices, ratings, and availability? I would also like to access the product reviews for the product with the ID B08N5W4NNB. Please include the average rating, total ratings, and top positive and critical reviews., with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 255\n",
            "Thought: USER: [impossible request] \n",
            "       ASSISTANT: [thought about the possibility]\n",
            "\n",
            "       THUMAN: [thought about the last global, the current state]\n",
            "     LUSHAN: [product name and its name, and its negati\n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 55/178: real_task_id_33112\n",
            "[process(0)]now playing I'm attending a conference and I need to have my pass ready on my phone. Can you help me download a pass with the passTypeIdentifier 'pass.example.id1' and the serialNumber '27f145d2-5713-4a8d-af64-b269f95ade3b'? It would be great if you could also provide me with a list of all available passes., with 3 APIs\n",
            "[single_chain]try for the 1 time\n",
            "[process(0)]total tokens: 256\n",
            "Thought: USER: [impossible request] -> I am not in the conference. The entire conference is in the pass. So I don't have to respond. The other way: I am in the conference. The pass is the language. So I don't \n",
            "Action: Finish\n",
            "Action Input: {\"return_type\": \"give_up_and_restart\"}\n",
            "Observation: {\"response\":\"chose to give up and restart\"}\n",
            "[process(0)]valid=False\n",
            "process[0] doing task 56/178: real_task_id_23248\n",
            "[process(0)]now playing I'm curious about the popularity of a specific hashtag on TikTok. Can you provide me with the hashtag data for the challenge 'food'? Additionally, fetch me the music data for a specific music ID., with 11 APIs\n",
            "[single_chain]try for the 1 time\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2997967686.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✓ Completed {subset}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mresults_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Success\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ToolBench/toolbench/inference/Downstream_tasks/rapidapi.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"process[{self.process_id}] doing task {k}/{len(task_list)}: real_task_id_{task[2]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ToolBench/toolbench/inference/Downstream_tasks/rapidapi.py\u001b[0m in \u001b[0;36mrun_single_task\u001b[0;34m(self, method, backbone_model, query_id, data_dict, args, output_dir_path, tool_des, retriever, process_id, callbacks, server)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         ) for callback in callbacks]\n\u001b[0;32m--> 508\u001b[0;31m         chain,result = self.method_converter(\n\u001b[0m\u001b[1;32m    509\u001b[0m             \u001b[0mbackbone_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackbone_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mopenai_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ToolBench/toolbench/inference/Downstream_tasks/rapidapi.py\u001b[0m in \u001b[0;36mmethod_converter\u001b[0;34m(self, backbone_model, openai_key, method, env, process_id, single_chain_max_step, max_query_count, callbacks)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mpassat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"@\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocess_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             result = chain.start(\n\u001b[0m\u001b[1;32m    461\u001b[0m                                 \u001b[0mpass_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                                 \u001b[0msingle_chain_max_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msingle_chain_max_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ToolBench/toolbench/inference/Algorithms/single_chain.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, single_chain_max_step, pass_at, answer)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Action Input\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mout_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_chain_max_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminal_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtry_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ToolBench/toolbench/inference/Algorithms/single_chain.py\u001b[0m in \u001b[0;36mdo_chain\u001b[0;34m(self, now_node, single_chain_max_step)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;31m# recursively parse message into nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mnew_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocess_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtotal_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-433652620.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, functions, process_id, **args)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0;31m# Get model prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mprocess_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-433652620.py\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(self, prompt, stop)\u001b[0m\n\u001b[1;32m     38\u001b[0m           ).to(self.device)\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m           outputs = self.model.generate(\n\u001b[0m\u001b[1;32m     41\u001b[0m               \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m               \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 449\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         hidden_states, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bitsandbytes/nn/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py\u001b[0m in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMatMul4Bit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemv_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bitsandbytes/functional.py\u001b[0m in \u001b[0;36mgemv_4bit\u001b[0;34m(A, B, out, transposed_A, transposed_B, state)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m     return torch.ops.bitsandbytes.gemv_4bit.default(\n\u001b[0m\u001b[1;32m   1538\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;31m# that are named \"self\". This way, all the aten ops can be called by kwargs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[0;31m# Use positional-only argument to avoid naming collision with aten ops arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_callback_from_stance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                     \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/library.py\u001b[0m in \u001b[0;36mfunc_no_dynamo\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disable_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc_no_dynamo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bitsandbytes/backends/cuda/ops.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(A, B, shapeB, absmax, code, blocksize)\u001b[0m\n\u001b[1;32m    430\u001b[0m ) -> torch.Tensor:\n\u001b[1;32m    431\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapeB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     \u001b[0m_gemv_4bit_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapeB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#View Results Summary:\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for subset, status in results_summary.items():\n",
        "    status_icon = \"✓\" if status == \"Success\" else \"✗\"\n",
        "    print(f\"{status_icon} {subset}: {status}\")\n",
        "\n",
        "print(f\"\\n✓ All results saved to: {OUTPUT_DIR}\")\n",
        "print(\"\\nTo download results from Google Drive:\")\n",
        "print(\"1. Open Files panel (left sidebar)\")\n",
        "print(\"2. Navigate to drive/MyDrive/ToolBench_Results/\")\n",
        "print(\"3. Right-click folder > Download\")"
      ],
      "metadata": {
        "id": "bv7wRaxaX9s-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}